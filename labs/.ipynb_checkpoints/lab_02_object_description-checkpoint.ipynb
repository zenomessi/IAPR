{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR 2020:][iapr2020] Lab 2 â€’  Object description\n",
    "\n",
    "**Authors:** first_name_1 last_name_1, first_name_2 last_name_2, first_name_3 last_name_3  \n",
    "**Due date:** 24.04.2020\n",
    "\n",
    "[iapr2020]: https://github.com/LTS5/iapr-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract relevant data\n",
    "We first need to extract the `lab-02-data.tar.gz` archive.\n",
    "To this end, we use the [tarfile] module from the Python standard library.\n",
    "\n",
    "[tarfile]: https://docs.python.org/3.6/library/tarfile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "data_base_path = os.path.join(os.pardir, 'data')\n",
    "data_folder = 'lab-02-data'\n",
    "tar_path = os.path.join(data_base_path, data_folder + '.tar.gz')\n",
    "with tarfile.open(tar_path, mode='r:gz') as tar:\n",
    "    tar.extractall(path=data_base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means it worked!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "In the `lab-02-data/part1` folder, you will find 28x28 grey-scale pictures of handwritten \"0\" and \"1\".\n",
    "These digits have been extracted from MNIST dataset (http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "Your goal is to extract, from each of those images, a 2-dimensional feature vector (i.e. 2 features) and to plot them all on a 2D graph.\n",
    "If you have chosen good features, the vectors of the \"0\"'s should nicely cluster in one part of the plane and those of the \"1\"'s in another.\n",
    "\n",
    "Please try first the Fourier Descriptors.\n",
    "You can make several attempts: e.g. with and without invariance to rotation, translation, scaling, etc.\n",
    "You can also for instance rotate the images and assess the invariance in rotation.\n",
    "\n",
    "**Note:** for the Fourier descriptors, the u_k signal has to be constructed by following the contour point after point.\n",
    "Some pre-processing (image binarization, possibly some Mathematical Morphology) might be useful.\n",
    "\n",
    "Then feel free to try other features, the more you try, the better it will be (for you)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load images\n",
    "data_base_path = os.path.join(os.pardir, 'data')\n",
    "data_folder = 'lab-02-data'\n",
    "#  Load zeros\n",
    "zeros_path = os.path.join(data_base_path, data_folder, 'part1', '0')\n",
    "zeros_names = [nm for nm in os.listdir(zeros_path) if '.png' in nm]  # make sure to only load .png\n",
    "zeros_names.sort()  # sort file names\n",
    "ic = skimage.io.imread_collection([os.path.join(zeros_path, nm) for nm in zeros_names])\n",
    "zeros_im = skimage.io.concatenate_images(ic)\n",
    "#  Load ones\n",
    "ones_path = os.path.join(data_base_path, data_folder, 'part1', '1')\n",
    "ones_names = [nm for nm in os.listdir(ones_path) if '.png' in nm]  # make sure to only load .png\n",
    "ones_names.sort()  # sort file names\n",
    "ic = skimage.io.imread_collection(([os.path.join(ones_path, nm) for nm in ones_names]))\n",
    "ones_im = skimage.io.concatenate_images(ic)\n",
    "\n",
    "# Plot images\n",
    "fig, axes = plt.subplots(2, len(zeros_im), figsize=(12, 3))\n",
    "for ax, im, nm in zip(axes[0], zeros_im, zeros_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "for ax, im, nm in zip(axes[1], ones_im, ones_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS AND FUNCTIONS DEFINITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries once and for all\n",
    "import skimage.filters\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from skimage import feature\n",
    "from skimage import exposure\n",
    "from scipy import ndimage\n",
    "from skimage import measure\n",
    "from skimage import filters\n",
    "from skimage import morphology\n",
    "from skimage import util\n",
    "from skimage.segmentation import active_contour\n",
    "import math\n",
    "import cmath\n",
    "\n",
    "\n",
    "# function that computes the area enclosed by a set of points\n",
    "def PolyArea(x,y):\n",
    "    return 0.5*np.abs(np.dot(x,np.roll(y,1))-np.dot(y,np.roll(x,1)))\n",
    "\n",
    "def PolyPerim(c):\n",
    "    res=0\n",
    "    for i in range(len(c)-1):\n",
    "        res+=np.sqrt((c[i+1,0]-c[i,0])**2+(c[i+1,1]-c[i,1])**2)\n",
    "    res+=np.sqrt((c[0,0]-c[-1,0])**2+(c[0,1]-c[-1,1])**2)\n",
    "    return res\n",
    "\n",
    "def binarize(images, i):\n",
    "    res=[]\n",
    "    for im in images:\n",
    "        res.append(im[:]>i)\n",
    "    return res\n",
    "\n",
    "def morpho_operation(images):\n",
    "    res=[]\n",
    "    for im in images:\n",
    "#         im=morphology.binary_closing(im,morphology.square(2))\n",
    "#         im=morphology.binary_dilation(im,morphology.square(2))\n",
    "        res.append(im)\n",
    "    return res\n",
    "\n",
    "def biggest_contours(images):\n",
    "    res=[]\n",
    "    for im in images:\n",
    "        contours=measure.find_contours(im, 0.01)\n",
    "        contours_areas=[PolyArea(x[:,0],x[:,1]) for x in contours]\n",
    "        res.append(contours[np.argmax(np.asarray(contours_areas))])\n",
    "    return res\n",
    "\n",
    "def contour2complex(contours):\n",
    "    res=[]\n",
    "    for cont in contours:\n",
    "        res.append([complex(c[0],c[1]) for c in cont])\n",
    "    return res\n",
    "\n",
    "def fourier(cont, i):\n",
    "    res=[]\n",
    "    for u in cont:\n",
    "        ftu=[]\n",
    "        n=float(len(u))\n",
    "        for l in range(0,i):\n",
    "            temp=sum([u_i*np.exp(-complex(0,1.)*2*math.pi*k*l/n) for (k, u_i) in enumerate(u)])\n",
    "            ftu.append(temp)\n",
    "        res.append(ftu)\n",
    "    return res\n",
    "\n",
    "def rotate_contours(cont, phi):\n",
    "    res=[]\n",
    "    for u in cont:\n",
    "        z_u=[]\n",
    "        for z in u:\n",
    "            z_u.append(np.exp(complex(0.,phi))*z)\n",
    "        res.append(z_u)\n",
    "    return res\n",
    "\n",
    "# Freeman code\n",
    "\n",
    "# This list contains the directions\n",
    "coding_t=[[2, 0], [1, 1], [0,2], [-1,1], [-2,0],[-1,-1], [0,-2], [1,-1]]\n",
    "\n",
    "def chain_code(cont, mindist):\n",
    "    res=[]\n",
    "    for contour in cont:\n",
    "    #     We first have to approximate the curve\n",
    "        approx=[]\n",
    "        approx.append(contour[0].round())\n",
    "        for p in contour:\n",
    "            if np.linalg.norm(p.round()-approx[-1]) >= mindist:\n",
    "                approx.append(p.round())\n",
    "        if np.linalg.norm(approx[0]-approx[-1]) < mindist:\n",
    "            approx.pop(-1)\n",
    "    #     Then we create the chain\n",
    "        chain=[]\n",
    "        for i in range(0,len(approx)-1):\n",
    "            x=approx[i+1][0]-approx[i][0]\n",
    "            y=approx[i+1][1]-approx[i][1]\n",
    "    #         normalize (== compute trigonometrical operations)\n",
    "            norm=np.sqrt(x**2+y**2)\n",
    "            x/=norm\n",
    "            y/=norm\n",
    "            x=int(np.sign(x)*round(2*x**2))\n",
    "            y=int(np.sign(y)*round(2*y**2))\n",
    "            chain.append(coding_t.index([x,y]))\n",
    "        x_last=approx[0][0]-approx[-1][0]\n",
    "        y_last=approx[0][1]-approx[-1][1]\n",
    "        norm_last=np.sqrt(x_last**2+y_last**2)\n",
    "        x_last/=norm_last\n",
    "        y_last/=norm_last\n",
    "        x_last=int(np.sign(x_last)*round(2*x_last**2))\n",
    "        y_last=int(np.sign(y_last)*round(2*y_last**2))\n",
    "        chain.append(coding_t.index([x_last, y_last]))\n",
    "        res.append(chain)\n",
    "#     print(res)\n",
    "    return res\n",
    "\n",
    "# invariance in the starting point\n",
    "def freeman_start_inv(free):\n",
    "    res=[]\n",
    "    for l in free:\n",
    "        n=np.zeros((len(l),1))\n",
    "        m=0\n",
    "        for j, k in enumerate(l):\n",
    "            m+=pow(10, j)*k\n",
    "        n[0]=m\n",
    "        for i in range(1, len(l)):\n",
    "            m=0\n",
    "            l_perm=l[len(l)-i:len(l)]+l[0:len(l)-i]\n",
    "            for j, k in enumerate(l_perm):\n",
    "                m+=pow(10, len(l_perm)-j-1)*k\n",
    "            n[i]=m\n",
    "        l_ordered=l[len(l)-np.argmin(n):len(l)]+l[0:len(l)-np.argmin(n)]\n",
    "        res.append(l_ordered)\n",
    "    return res\n",
    "\n",
    "# invariance in rotation\n",
    "def freeman_rot_inv(free):\n",
    "    res=[]\n",
    "    for l in free:\n",
    "        f=[]\n",
    "        for i in range(0, len(l)-1):\n",
    "            f.append((l[i+1]-l[i])%8)\n",
    "        f.append((l[0]-l[-1])%8)\n",
    "        res.append(f) \n",
    "    return res\n",
    "\n",
    "\n",
    "# editing distance (levenshtein)\n",
    "def Levenshtein(list_1, list_2):\n",
    "    size_1=len(list_1)+1\n",
    "    size_2=len(list_2)+1\n",
    "    d=np.zeros((size_1,size_2))\n",
    "    for i in range(size_1):\n",
    "        d[i, 0]=i\n",
    "    for j in range(size_2):\n",
    "        d[0, j] = j \n",
    "    \n",
    "    for i in range(1, size_1):\n",
    "        for j in range(1, size_2):\n",
    "            if list_1[i-1] == list_2[j-1]:\n",
    "                subCost=0\n",
    "            else:\n",
    "                subCost=1\n",
    "            d[i, j] = min(d[i-1, j]+1, d[i, j-1]+1, d[i-1,j-1]+subCost)\n",
    "    return d[len(list_1), len(list_2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Fourier descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binarization\n",
    "zeros_bin=binarize(zeros_im,100)\n",
    "ones_bin=binarize(ones_im, 100)\n",
    "\n",
    "               \n",
    "#Morphological operations\n",
    "#The definitions of the morphological functions was moved to the cell above\n",
    "zeros_dilated=morpho_operation(zeros_bin)\n",
    "ones_dilated=morpho_operation(ones_bin)\n",
    "\n",
    "# Create contours\n",
    "outer_0=biggest_contours(zeros_dilated)\n",
    "outer_1=biggest_contours(ones_dilated)\n",
    "\n",
    "#plot everything\n",
    "fig, axes = plt.subplots(2, len(zeros_im), figsize=(24, 6))\n",
    "fig.suptitle('Dilated binarized image with contours')\n",
    "for ax, im, nm in zip(axes[0], zeros_dilated, zeros_names):\n",
    "# for ax, im, nm in zip(axes[1], zeros_bin, zeros_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "for ax, contour in zip(axes[0],outer_0):\n",
    "        ax.plot(contour[:, 1], contour[:, 0], linewidth=2)#x and y are in opposite in an image\n",
    "for ax, im, nm in zip(axes[1], ones_dilated, ones_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "for ax, contour in zip(axes[1],outer_1):\n",
    "        ax.plot(contour[:, 1], contour[:, 0], linewidth=2)#x and y are in opposite in an image\n",
    "plt.show()\n",
    "\n",
    "### creating the complex numbers from the contours\n",
    "us_0=contour2complex(outer_0)\n",
    "us_1=contour2complex(outer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "# Compute 10 fourier coefficients\n",
    "ft_0=fourier(us_0,10)\n",
    "ft_1=fourier(us_1,10)\n",
    "\n",
    "# Take their norm\n",
    "ft_0_norm=[[abs(u) for u in f] for f in ft_0]\n",
    "ft_1_norm=[[abs(u) for u in f] for f in ft_1]\n",
    "\n",
    "# And plot everything\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "fig.suptitle(\"2 Fourier coefficients for zeros and ones\")\n",
    "for f in ft_0_norm:\n",
    "    ax.plot(f[1], f[4], '*', markersize='20')\n",
    "\n",
    "for f in ft_1_norm:\n",
    "    ax.plot(f[1], f[4], '.',markersize='20')\n",
    "ax.set_xlabel('Fourier coefficient 1')\n",
    "ax.set_ylabel('Fourier coefficient 2')\n",
    "ax.legend(zeros_names+ones_names, loc='lower right', bbox_to_anchor=(1.2, 0))\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure( figsize=(12, 10))\n",
    "fig.suptitle(\"3 Fourier coefficients for zeros and ones\")\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for f in ft_0_norm:\n",
    "    ax.scatter(f[1], f[2], f[3], s=200,marker='.')\n",
    "    ax.plot([f[1],f[1]], [f[2],f[2]], [0, f[3]])\n",
    "for f in ft_1_norm:\n",
    "    ax.scatter(f[1], f[2], f[3], s=100, marker='^')\n",
    "    ax.plot([f[1],f[1]], [f[2],f[2]], [0, f[3]])\n",
    "ax.set_xlabel('Norm of Fourier coefficient 1')\n",
    "ax.set_ylabel('Norm of Fourier coefficient 2')\n",
    "ax.set_zlabel('Norm of Fourier coefficient 3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assess rotation invariance\n",
    "# rotate the complex numbers of the contours\n",
    "xmax=30\n",
    "xmin=-30\n",
    "\n",
    "# rotated and rerotated contours\n",
    "us_0_rotated=rotate_contours(us_0, math.pi)\n",
    "us_0_rerotated=rotate_contours(us_0_rotated, math.pi)\n",
    "    \n",
    "fig, axes = plt.subplots(1, len(zeros_im), figsize=(24, 6))\n",
    "fig.suptitle('Transformed contours of zeros')\n",
    "for ax, im1,im2,im3, nm in zip(axes, us_0, us_0_rotated,us_0_rerotated, zeros_names):\n",
    "    ax.plot([u.imag for u in im1],[u.real for u in im1])\n",
    "    ax.plot([u.imag for u in im2],[u.real for u in im2])\n",
    "#     ax.plot([u.imag+1 for u in im3],[u.real+1 for u in im3])\n",
    "    ax.set(xlim=(xmin, xmax), ylim=(xmin, xmax))\n",
    "    ax.set_title(nm)\n",
    "    ax.legend(['original', 'rotated'], loc='lower right', bbox_to_anchor=(1.2, 0))\n",
    "plt.show()\n",
    "\n",
    "#fourier descriptors of the rotated contour\n",
    "ft_0_rotated=fourier(us_0_rotated,10)\n",
    "    \n",
    "ft_0_rotated_norm=[[abs(u) for u in f] for f in ft_0_rotated]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "fig.suptitle('Comparison of fourier coefficient for original and rotated contours')\n",
    "for i,f in enumerate(ft_0_norm):\n",
    "    if i==0 :\n",
    "        ax.plot(f[1], f[2], '^', markersize='20', fillstyle='none', label='original zeros contours')\n",
    "    else :\n",
    "        ax.plot(f[1], f[2], '^', markersize='20', fillstyle='none')\n",
    "for i,f in enumerate(ft_1_norm):\n",
    "    if i==0:\n",
    "        ax.plot(f[1], f[2], '.', markersize='20', label='original ones contours')\n",
    "    else :\n",
    "        ax.plot(f[1], f[2], '.', markersize='20')\n",
    "        \n",
    "for i,f in enumerate(ft_0_rotated_norm):\n",
    "    if i==0 :\n",
    "        ax.plot(f[1], f[2], '*', markersize='10', label='rotated zeros contours')\n",
    "    else :\n",
    "        ax.plot(f[1], f[2], '*', markersize='10')\n",
    "ax.set_xlabel('Norm of Fourier coefficient 1')\n",
    "ax.set_ylabel('Norm of Fourier coefficient 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion: Fourier descriptors\n",
    "\n",
    "We started by binarizing the images, performing some mathematical morphology (dilation) and finding contours using the find contours function, in a similar strategy to lab 1. The picture 1_8.png has small granules that are also recognized by the find_contours function. To ensure we wre working on the number and not the granules we calculated the size of the contours and took the biggest one. Then, we used this as the input for creating our complex numbers. We could then calculate our ten fourier coefficients for each number. To choose which descriptors to use to seperate our ones and zeros, we kept several things in mind: The location of the objects being encoded only into the first descriptor, we can thus be translation invariant by ignoring the zeroth coefficient. Rotation of objects as well as the choice of the first point only affects their phase, therefore by taking only the amplitudes, we can be rotation invariant and insensitive to the choice of our starting point. We therefore plotted the amplitude of the first and second coefficients and this adequately separated the ones and zeros: with zeros being smaller than 150 along coefficient 1 and ones being larger than 150 along coefficient 1 (In fact, for seperating ones and zeros just the first fourier coefficient is necessary). We tested whether plotting 3 coefficients would help cluster them further: although this adequately seperates the two ones that have a more complex shape due to the serif, this does not help seperate ones and zeros. This is probably as there in generally little information encoded in the higher frequencies for the ones and zeros. We tested the rotation invariance by rotating our contours by 180 degrees, and indeed there was no effect on the plot of fourier descriptors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Additional method(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perimeter, Area and Compacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## contour based\n",
    "fig, ax = plt.subplots(3, 1, figsize=(12, 15))\n",
    "ax[0].set_title('Area')\n",
    "ax[0].plot(range(len(outer_0)), [PolyArea(c[:,0], c[:,1]) for c in outer_0],'k.', markersize='20')\n",
    "ax[0].plot(range(len(outer_1)), [PolyArea(c[:,0], c[:,1]) for c in outer_1],'r+', markersize='20')\n",
    "ax[0].legend(['zeros', 'ones'])\n",
    "ax[0].set_xlabel('index of image')\n",
    "ax[0].set_ylabel('Area')\n",
    "\n",
    "ax[1].set_title('Perimeter')\n",
    "ax[1].plot(range(len(outer_0)), [PolyPerim(c) for c in outer_0],'k.', markersize='20')\n",
    "ax[1].plot(range(len(outer_1)), [PolyPerim(c) for c in outer_1],'r+', markersize='20')\n",
    "ax[1].legend(['zeros', 'ones'])\n",
    "ax[1].set_xlabel('index of image')\n",
    "ax[1].set_ylabel('Perimeter')\n",
    "\n",
    "ax[2].set_title('Compacity')\n",
    "ax[2].plot(range(len(outer_0)), [PolyPerim(c)**2/PolyArea(c[:,0], c[:,1]) for c in outer_0],'k.', markersize='20')\n",
    "ax[2].plot(range(len(outer_1)), [PolyPerim(c)**2/PolyArea(c[:,0], c[:,1]) for c in outer_1],'r+', markersize='20')\n",
    "ax[2].legend(['zeros', 'ones'])\n",
    "ax[2].set_xlabel('index of image')\n",
    "ax[2].set_ylabel('Compacity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region based\n",
    "\n",
    "def Area_region(c):\n",
    "    return np.count_nonzero(c)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "ax.set_title('Area')\n",
    "ax.plot(range(len(outer_0)), [Area_region(c) for c in zeros_dilated],'k.', markersize='20')\n",
    "ax.plot(range(len(outer_0)), [Area_region(c) for c in ones_dilated],'r+', markersize='20')\n",
    "# ax[0].plot(range(len(outer_1)), [PolyArea(c[:,0], c[:,1]) for c in outer_1],'r+', markersize='20')\n",
    "ax.legend(['zeros', 'ones'])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion Additional Methods: Region based descriptors\n",
    "\n",
    "We tested seperating our objects using simple descriptors such as perimeter, area and compacity. When working with the outside contours, this worked relatively well. The zeros for example have a consitently larger area and are more compact. Perimeter does not work well as a descriptor due to two of the ones having a serif and thus a larger perimeter. When utilising regions... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "\n",
    "# transform the image back into uints\n",
    "zeros_mask=[]\n",
    "ones_mask=[]\n",
    "for i,im in enumerate(zeros_bin):\n",
    "    zeros_mask.append(np.zeros_like(im, dtype='uint8'))\n",
    "    zeros_mask[i][im]=1\n",
    "for i,im in enumerate(ones_bin):\n",
    "    ones_mask.append(np.zeros_like(im, dtype='uint8'))\n",
    "    ones_mask[i][im]=1\n",
    "\n",
    "M_0=[]\n",
    "M_1=[]\n",
    "for im in zeros_mask:\n",
    "    M_0.append(measure.moments(im))\n",
    "for im in ones_mask:\n",
    "    M_1.append(measure.moments(im))\n",
    "    \n",
    "mean_0=[]\n",
    "mean_1=[]\n",
    "for m in M_0:\n",
    "    mean_0.append([m[1,0]/m[0,0], m[0,1]/m[0,0]])\n",
    "for m in M_1:\n",
    "    mean_1.append([m[1,0]/m[0,0], m[0,1]/m[0,0]])\n",
    "\n",
    "    \n",
    "M_0_c=[]\n",
    "M_1_c=[]\n",
    "for im in zeros_mask:\n",
    "    M_0_c.append(measure.moments_central(im))\n",
    "for im in ones_mask:\n",
    "    M_1_c.append(measure.moments_central(im))\n",
    "    \n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "for i, (mom_0, mom_1) in enumerate(zip(M_0, M_1)):\n",
    "    ax[0].plot(i, mom_0[1,1]-mom_0[1,0]*mom_0[0,1]/mom_0[0,0], 'k.', markersize='20')\n",
    "    ax[0].plot(i, mom_1[1,1]-mom_1[1,0]*mom_1[0,1]/mom_1[0,0], 'r+',markersize='20')\n",
    "    ax[0].legend(['zeros', 'ones'])\n",
    "    ax[0].set_title('Translation invariant')\n",
    "    ax[0].set_xlabel('image index', fontsize=16)\n",
    "    ax[0].set_ylabel('centered moment 'r'$\\displaystyle\\mu_{1,1}$',fontsize=16)\n",
    "\n",
    "for i, (mom_0, mom_1) in enumerate(zip(M_0_c, M_1_c)):\n",
    "    ax[1].plot(i, (mom_0[2,0]+mom_0[2,0]), 'k.', markersize='20')\n",
    "    ax[1].plot(i, (mom_1[2,0]+mom_1[2,0]), 'r+', markersize='20')\n",
    "    ax[1].legend(['zeros', 'ones'])\n",
    "    ax[1].set_title('Translation and rotation invariant')\n",
    "    ax[1].set_xlabel('image index',fontsize=16)\n",
    "    ax[1].set_ylabel(r'$\\displaystyle M_1$',fontsize=16)\n",
    "plt.show()\n",
    "    \n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "for i, (mom_0, mom_1) in enumerate(zip(M_0_c, M_1_c)):\n",
    "    ax[0].plot( (mom_0[2,0])/mom_0[0,0]**2,(mom_0[0,2])/mom_0[0,0]**2, 'k.', markersize='20')\n",
    "    ax[0].plot((mom_1[2,0])/mom_1[0,0]**2, (mom_1[0,2])/mom_1[0,0]**2, 'r+', markersize='20')\n",
    "    ax[0].legend(['zeros', 'ones'])\n",
    "    ax[0].set_title('Translation and scaling invariant, 2 descriptors')\n",
    "    ax[0].set_xlabel('standard centered moment 'r'$\\displaystyle\\eta_{2,0}$',fontsize=16)\n",
    "    ax[0].set_ylabel('standard centered moment 'r'$\\displaystyle\\eta_{0,2}$',fontsize=16)\n",
    "\n",
    "for i, (mom_0, mom_1) in enumerate(zip(M_0_c, M_1_c)):\n",
    "    ax[1].plot(i, (mom_0[2,0]+mom_0[2,0])/mom_0[0,0]**2, 'k.', markersize='20')\n",
    "    ax[1].plot(i, (mom_1[2,0]+mom_1[2,0])/mom_1[0,0]**2, 'r+', markersize='20')\n",
    "    ax[1].legend(['zeros', 'ones'])\n",
    "    ax[1].set_title('Translation and rotation and scaling invariant')\n",
    "    ax[1].set_xlabel('image index',fontsize=16)\n",
    "    ax[1].set_ylabel(r'$\\displaystyle M_1^\\prime$',fontsize=16)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "for i, (mom_0, mom_1) in enumerate(zip(M_0_c, M_1_c)):\n",
    "    ax[0].plot( (mom_0[2,0]+mom_0[2,0])/mom_0[0,0]**2, ((mom_0[2,0]/mom_0[0,2])**2-4*mom_0[1,1]**2)/mom_0[0,0]**4, 'k.', markersize='20')\n",
    "    ax[0].plot((mom_1[2,0]+mom_1[2,0])/mom_1[0,0]**2, ((mom_1[2,0]-mom_1[0,2])**2-4*mom_1[1,1]**2)/mom_1[0,0]**4, 'r+', markersize='20')\n",
    "    ax[0].legend(['zeros', 'ones'])\n",
    "    ax[0].set_title('Translation and rotation and scaling invariant, 2 descriptors')\n",
    "    ax[0].set_ylabel(r'$\\displaystyle M_2^\\prime$',fontsize=16)\n",
    "    ax[0].set_xlabel(r'$\\displaystyle M_1^\\prime$',fontsize=16)\n",
    "    \n",
    "for i, (mom_0, mom_1) in enumerate(zip(M_0_c, M_1_c)):\n",
    "    ax[1].plot( (mom_0[2,0]+mom_0[2,0]), ((mom_0[2,0]-mom_0[0,2])**2-4*mom_0[1,1]**2), 'k.', markersize='20')\n",
    "    ax[1].plot((mom_1[2,0]+mom_1[2,0]), ((mom_1[2,0]-mom_1[0,2])**2-4*mom_1[1,1]**2), 'r+', markersize='20')\n",
    "    ax[1].legend(['zeros', 'ones'])\n",
    "    ax[1].set_title('Translation and rotation invariant, 2 descriptors')\n",
    "    ax[1].set_xlabel(r'$\\displaystyle M_1$',fontsize=16)\n",
    "    ax[1].set_ylabel(r'$\\displaystyle M_2$',fontsize=16)\n",
    "    \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to use the second moment to describe the contours, i.e. the variance. Skewness wouldn't have been an option because the ones the consist in just a bar, would have a low skewness like zeros. \n",
    "A translation invariant moment is not sufficient to discriminate the ones and zeros, but a translation and rotation invariant moment (1D feature) is able to cluster them.\n",
    "It seems that the scale invariance make it less good to discriminate between the zeros and ones, the version with just translation and rotation invariance works better. Since the zeros are significantly bigger than the ones, this is a useful information for discriminating them. The first rotation invariant centered moment is sufficient to discriminate the ones and the zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeman code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['text.usetex'] = False\n",
    "# create the freeman code with no invariance\n",
    "testarray=[np.array([[1,1],[2,1],[3,2],[3,3],[2,4],[1,4],[0,3],[0,2],[1,1]]), np.array([[1,1],[2,2]])]\n",
    "freeman_test=chain_code(testarray,1.)\n",
    "freeman_0_l=chain_code(outer_0,1.)\n",
    "freeman_1_l=chain_code(outer_1,1.)\n",
    "\n",
    "print(freeman_0_l[0])\n",
    "# testarray=[np.array([[1,1],[2,1],[3,2],[3,3],[2,4],[1,4],[0,3],[0,2]]), np.array([[1,1],[2,2]])]\n",
    "\n",
    "# print(freeman_test)\n",
    "f_rec=[]\n",
    "f_rec.append(outer_0[0][0,0])\n",
    "#starting point invariance\n",
    "# order the chain so than the starting point doesn't matter\n",
    "freeman_0_l_ordered=freeman_start_inv(freeman_0_l)\n",
    "freeman_1_l_ordered=freeman_start_inv(freeman_1_l)\n",
    "print(freeman_0_l_ordered[0])\n",
    "\n",
    "#rotation invariance\n",
    "freeman_0_l_final=freeman_rot_inv(freeman_0_l_ordered)\n",
    "freeman_1_l_final=freeman_rot_inv(freeman_1_l_ordered)\n",
    "for f in freeman_0_l_final:\n",
    "    print(f)\n",
    "# print(freeman_0_l_final)\n",
    "# for u, f in zip(outer_0,freeman_0_l):\n",
    "#     print(f)\n",
    "#     print(u)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "# for i in range(len(freeman_0_l_final)):\n",
    "#     for j in range(i+1,len(freeman_0_l_final)):\n",
    "#         ax.plot(i+j,Levenshtein(freeman_0_l_final[i],freeman_0_l_final[j]), 'k.')\n",
    "# #         print(Levenshtein(freeman_0_l_final[i],freeman_0_l_final[j]))\n",
    "# for i in range(len(freeman_1_l_final)):\n",
    "#     for j in range(i+1,len(freeman_1_l_final)):\n",
    "#         ax.plot(i+j,Levenshtein(freeman_1_l_final[i],freeman_1_l_final[j]), 'r+')\n",
    "# for i in range(len(freeman_0_l_final)):\n",
    "#     for j in range(i+1,len(freeman_1_l_final)):\n",
    "#         ax.plot(i+j,Levenshtein(freeman_0_l_final[i],freeman_1_l_final[j]), 'b^')\n",
    "for i in range(len(freeman_0_l_final)):\n",
    "#     for j in range(i+1,len(freeman_0_l_final)):\n",
    "    ax.plot(Levenshtein(freeman_0_l_final[6],freeman_0_l_final[i]),Levenshtein(freeman_1_l_final[6],freeman_0_l_final[i]), 'k.')\n",
    "    ax.plot(Levenshtein(freeman_0_l_final[6],freeman_1_l_final[i]),Levenshtein(freeman_1_l_final[6],freeman_1_l_final[i]), 'r+')\n",
    "#         ax.plot(i,Levenshtein(freeman_0_l_final[0],freeman_0_l_final[i]), 'k.')\n",
    "#         print(Levenshtein(freeman_0_l_final[i],freeman_0_l_final[j]))\n",
    "# for i in range(len(freeman_1_l_final)):\n",
    "#         ax.plot(i,Levenshtein(freeman_1_l_final[0],freeman_1_l_final[i]), 'r+')\n",
    "# for i in range(len(freeman_0_l_final)):\n",
    "#         ax.plot(i,Levenshtein(freeman_0_l_final[0],freeman_1_l_final[i]),  'b^')\n",
    "    ax.set_xlabel(\"Levenstein editing distance zeroth zero contour \")\n",
    "    ax.set_ylabel(\"Levenstein editing distance sixth one contour \")\n",
    "    ax.legend(['zeros', 'ones'])\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "for i in range(len(freeman_0_l_final)):\n",
    "        ax.plot(Levenshtein(freeman_0_l_final[0],freeman_0_l_final[i]),Levenshtein(freeman_1_l_final[0],freeman_0_l_final[i]),  'k.')\n",
    "        ax.plot(Levenshtein(freeman_0_l_final[0],freeman_1_l_final[i]),Levenshtein(freeman_1_l_final[0],freeman_1_l_final[i]),  'b^')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion: Freeman code\n",
    "    \n",
    "We tested using freeman codes to differentiate between ones and zeros. We first define the directions we will code, using the 8 nearest neighbours, and approximate the curve from the contours. Then we can generate the chain for each number. We inspected the contours of each number, and chose our reference images as those numbers which looked the most standard: for example the 9th zero and the 6th one. We utilised the Levenshtein distance to compute the smallest difference between each numbers contour and our reference one and zero. We plotted the Levenstein distance of the ones to the reference one and the Levenshtein distance of the zeros to the reference zero. From this we can see that the intraclass differences between ones and zeros are about the same. Additionally, as with the fourier descriptors, we can see that the two ones with a serif are more different that the others. In an attempt to seperate the two classes of numbers, we plotted a 2D graph, were one axis represents the Levenshtein distance to our reference one and the other axis represents the Lebenshtein distance to our reference zero. With two exceptions, we can mostly seperate the two classes. \n",
    "\n",
    "There are two reasons why we think the Freeman code does not work so well here: 1, the low resolution makes the contours quite rough and the creation of acurate chains challenging. Instead of having diagonals, the contours are sometimes shaped as stairs. As this is not consistent, the Freeman code therefore varies more significantly for two numbers that in reality should be more similar. 2, the Levenshtein distance is perhaps more suited to recognising differences in strings of letters, not in contours within a 2D plane. \n",
    "\n",
    "!!! Don't really see where you tested the invariances !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "The `lab-02-data/part2` folder contains grey-scale pictures of handwritten \"2\" and \"3\".\n",
    "Extract the same feature (typically 2 Fourier descriptors) as in part 1 also on these images and plot them on the same graph as the features of the \"0\" and \"1\".\n",
    "Is it possible to discriminate all these 4 digits with a 2-dimensional feature vector?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load twos\n",
    "twos_path = os.path.join(data_base_path, data_folder, 'part2', '2')\n",
    "twos_names = [nm for nm in os.listdir(twos_path) if '.png' in nm]  # make sure to only load .png\n",
    "twos_names.sort()  # sort file names\n",
    "ic = skimage.io.imread_collection([os.path.join(twos_path, nm) for nm in twos_names])\n",
    "twos_im = skimage.io.concatenate_images(ic)\n",
    "#  Load threes\n",
    "threes_path = os.path.join(data_base_path, data_folder, 'part2', '3')\n",
    "threes_names = [nm for nm in os.listdir(threes_path) if '.png' in nm]  # make sure to only load .png\n",
    "threes_names.sort()  # sort file names\n",
    "ic = skimage.io.imread_collection(([os.path.join(threes_path, nm) for nm in threes_names]))\n",
    "threes_im = skimage.io.concatenate_images(ic)\n",
    "\n",
    "# Plot images\n",
    "fig, axes = plt.subplots(2, len(twos_im), figsize=(12, 3))\n",
    "for ax, im, nm in zip(axes[0], twos_im, twos_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "for ax, im, nm in zip(axes[1], threes_im, threes_names):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twos_bin=binarize(twos_im, 100)\n",
    "threes_bin=binarize(threes_im,100)\n",
    "\n",
    "twos_dilated=morpho_operation(twos_bin)\n",
    "threes_dilated=morpho_operation(threes_bin)\n",
    "    \n",
    "outer_2=biggest_contours(twos_dilated)\n",
    "outer_3=biggest_contours(threes_dilated)\n",
    "\n",
    "### creating the complex numbers from the contours\n",
    "us_2=contour2complex(outer_2)\n",
    "us_3=contour2complex(outer_3)\n",
    "\n",
    "ft_2=fourier(us_2, 10)\n",
    "ft_3=fourier(us_3, 10)\n",
    "\n",
    "# Take their norm\n",
    "ft_2_norm=[[abs(u) for u in f] for f in ft_2]\n",
    "ft_3_norm=[[abs(u) for u in f] for f in ft_3]\n",
    "\n",
    "# Plot everything\n",
    "\n",
    "# Plot binarized images with contours\n",
    "fig, axes = plt.subplots(2, len(twos_im), figsize=(12, 3))\n",
    "for ax, im, nm, cont in zip(axes[0], twos_im, twos_names, outer_2):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.plot(cont[:, 1], cont[:, 0], linewidth=2)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "for ax, im, nm, cont in zip(axes[1], threes_im, threes_names, outer_3):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.plot(cont[:, 1], cont[:, 0], linewidth=2)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(nm)\n",
    "    \n",
    "#Fourier descriptors\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "for i,f in enumerate(ft_0_norm):\n",
    "    if(i==0):\n",
    "        ax.plot(f[1], f[3], '*', markersize='10', label='zeros')\n",
    "    else:\n",
    "        ax.plot(f[1], f[3], '*', markersize='10')\n",
    "for i,f in enumerate(ft_1_norm):\n",
    "    if(i==0):\n",
    "        ax.plot(f[1], f[3], '.', markersize='10', label='ones')\n",
    "    else:\n",
    "        ax.plot(f[1], f[3], '.', markersize='10')\n",
    "for i,f in enumerate(ft_2_norm):\n",
    "    if(i==0):\n",
    "        ax.plot(f[1], f[3], '^', markersize='10', label='twos')\n",
    "    else:\n",
    "        ax.plot(f[1], f[3], '^', markersize='10')\n",
    "for i,f in enumerate(ft_3_norm):\n",
    "    if(i==0):\n",
    "        ax.plot(f[1], f[3], '+', markersize='10', label='threes')\n",
    "    else:\n",
    "        ax.plot(f[1], f[3], '+', markersize='10')\n",
    "# ax.set_xlabel('Ratio of fourier coefficients {}/{}'.format(1,4))\n",
    "# ax.set_ylabel('Ratio of fourier coefficients {}/{}'.format(3,4))\n",
    "ax.set_xlabel('Fourier coefficient {}'.format(1))\n",
    "ax.set_ylabel('Fourier coefficient {}'.format(3))\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for f in ft_0_norm:\n",
    "    ax.scatter(f[1], f[2], f[3], s=200,marker='*')\n",
    "    ax.plot([f[1],f[1]], [f[2],f[2]], [0, f[3]])\n",
    "for f in ft_1_norm:\n",
    "    ax.scatter(f[1], f[2], f[3], s=100, marker='.')\n",
    "    ax.plot([f[1],f[1]], [f[2],f[2]], [0, f[3]])\n",
    "for f in ft_2_norm:\n",
    "    ax.scatter(f[1], f[2], f[3], s=200,marker='^')\n",
    "    ax.plot([f[1],f[1]], [f[2],f[2]], [0, f[3]])\n",
    "for f in ft_3_norm:\n",
    "    ax.scatter(f[1], f[2], f[3], s=200,marker='+')\n",
    "    ax.plot([f[1],f[1]], [f[2],f[2]], [0, f[3]])\n",
    "ax.set_xlabel('Fourier coefficient 1')\n",
    "ax.set_ylabel('Fourier coefficient 2')\n",
    "ax.set_zlabel('Fourier coefficient 3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion: Fourier descriptors\n",
    "\n",
    "We followed the same strategy as in part 1 for the segmentation and creation of fourier descriptors for the ones and zeros. We similarly plotted all four numbers as the amplitude of coefficient 1 vs the amplitude of coefficient 2. We additionally made these scale invariant by normalising by the 4th coefficient. This was not adequate to seperate the four numbers so we tried plotting the first three descriptors in a 3D plot. From here we could see that while the first coefficient was useful for separating the ones and zeros, the third coefficient was useful for separating the twos and threes. However, the 2 ones with the serif plot as outliers closer to the twos and threes. Therefore no, it is not possible to separate all four numbers with just a 2D feature vector, there will always be some outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Additional method(s) and conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(12, 15))\n",
    "\n",
    "#Moments\n",
    "twos_mask=[]\n",
    "threes_mask=[]\n",
    "for i,im in enumerate(twos_bin):\n",
    "    twos_mask.append(np.zeros_like(im, dtype='uint8'))\n",
    "    twos_mask[i][im]=1\n",
    "for i,im in enumerate(threes_bin):\n",
    "    threes_mask.append(np.zeros_like(im, dtype='uint8'))\n",
    "    threes_mask[i][im]=1\n",
    "\n",
    "M_2_c=[]\n",
    "M_3_c=[]\n",
    "for im in twos_mask:\n",
    "    M_2_c.append(measure.moments_central(im))\n",
    "for im in threes_mask:\n",
    "    M_3_c.append(measure.moments_central(im))\n",
    "    \n",
    "# for i, (mom_0, mom_1) in enumerate(zip(M_0_c, M_1_c)):\n",
    "#     ax[1].plot(i, (mom_0[2,0]+mom_0[2,0]), 'k.', markersize='20')\n",
    "#     ax[1].plot(i, (mom_1[2,0]+mom_1[2,0]), 'r+', markersize='20')\n",
    "#     ax[1].legend(['zeros', 'ones'])\n",
    "#     ax[1].set_title('Translation and rotation invariant')\n",
    "#     ax[1].set_xlabel('image index',fontsize=16)\n",
    "#     ax[1].set_ylabel(r'$\\displaystyle M_1$',fontsize=16)\n",
    "# plt.show()\n",
    "    \n",
    "# ax[0].set_title('Area and skewness in x')\n",
    "# ax[0].plot([(mom_0[3,0]+mom_0[3,0]) for mom_0 in M_0_c], [PolyArea(c[:,0], c[:,1]) for c in outer_0],'k.', markersize='20')\n",
    "# ax[0].plot([(mom_0[3,0]+mom_0[3,0]) for mom_0 in M_1_c], [PolyArea(c[:,0], c[:,1]) for c in outer_1],'r+', markersize='20')\n",
    "# ax[0].plot([(mom_0[3,0]+mom_0[3,0]) for mom_0 in M_2_c], [PolyArea(c[:,0], c[:,1]) for c in outer_2],'g^', markersize='20')\n",
    "# ax[0].plot([(mom_0[3,0]+mom_0[3,0]) for mom_0 in M_3_c], [PolyArea(c[:,0], c[:,1]) for c in outer_3],'b.', markersize='20')\n",
    "\n",
    "ax[0].set_title('skewness in x and area (region based)')\n",
    "ax[0].plot([(mom_0[3,0]+mom_0[3,0]) for mom_0 in M_0_c], [Area_region(c) for c in zeros_dilated],'k.', markersize='20')\n",
    "ax[0].plot([(mom_0[3,0]+mom_0[3,0]) for mom_0 in M_1_c], [Area_region(c) for c in ones_dilated],'r+', markersize='20')\n",
    "ax[0].plot([(mom_0[3,0]+mom_0[3,0]) for mom_0 in M_2_c], [Area_region(c) for c in twos_dilated],'g^', markersize='20')\n",
    "ax[0].plot([(mom_0[3,0]+mom_0[3,0]) for mom_0 in M_3_c], [Area_region(c) for c in threes_dilated],'b.', markersize='20')\n",
    "\n",
    "ax[1].set_title('Compacity and variance in y')\n",
    "ax[1].plot([(mom_0[0,2]+mom_0[0,2]) for mom_0 in M_0_c], [PolyPerim(c)**2/PolyArea(c[:,0], c[:,1]) for c in outer_0],'k.', markersize='20')\n",
    "ax[1].plot([(mom_0[0,2]+mom_0[0,2]) for mom_0 in M_1_c], [PolyPerim(c)**2/PolyArea(c[:,0], c[:,1]) for c in outer_1],'r+', markersize='20')\n",
    "ax[1].plot([(mom_0[0,2]+mom_0[0,2]) for mom_0 in M_2_c], [PolyPerim(c)**2/PolyArea(c[:,0], c[:,1]) for c in outer_2],'g^', markersize='20')\n",
    "ax[1].plot([(mom_0[0,2]+mom_0[0,2]) for mom_0 in M_3_c], [PolyPerim(c)**2/PolyArea(c[:,0], c[:,1]) for c in outer_3],'b.', markersize='20')\n",
    "\n",
    "\n",
    "# ax[2].set_title('fourier 3 and perimeter (contour based)')\n",
    "# ax[2].plot([f[3] for f in ft_0_norm], [PolyPerim(c)**2 for c in outer_0],'k.', markersize='20')\n",
    "# ax[2].plot([f[3] for f in ft_1_norm], [PolyPerim(c)**2 for c in outer_1],'r+', markersize='20')\n",
    "# ax[2].plot([f[3] for f in ft_2_norm], [PolyPerim(c)**2 for c in outer_2],'g^', markersize='20')\n",
    "# ax[2].plot([f[3] for f in ft_3_norm], [PolyPerim(c)**2 for c in outer_3],'b.', markersize='20')\n",
    "\n",
    "ax[2].set_title('fourier 3 and skewness in x')\n",
    "ax[2].plot([f[3] for f in ft_0_norm], [(mom_0[3,0]+mom_0[3,0]) for mom_0 in M_0_c],'k.', markersize='20')\n",
    "ax[2].plot([f[3] for f in ft_1_norm], [(mom_0[3,0]+mom_0[3,0]) for mom_0 in M_1_c],'r+', markersize='20')\n",
    "ax[2].plot([f[3] for f in ft_2_norm], [(mom_0[3,0]+mom_0[3,0]) for mom_0 in M_2_c],'g^', markersize='20')\n",
    "ax[2].plot([f[3] for f in ft_3_norm], [(mom_0[3,0]+mom_0[3,0]) for mom_0 in M_3_c],'b.', markersize='20')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion:\n",
    "\n",
    "We tried different ways to mix descriptors but it's difficult to find a descriptors that discriminate all shapes.\n",
    "\n",
    "Despite the exceptions, fourier descriptors are the best way to seperate the four numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
